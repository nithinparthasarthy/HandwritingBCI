{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook performs Step 1 of the RNN training process: time-warping the single letter data so that it\n",
    "#can be used to initialize the data-labeling HMM. Running this notebook will (slowly) time-warp all 10 sessions\n",
    "#and save the results in Step1_TimeWarping folder.\n",
    "\n",
    "#To run this notebook, you'll need the time warped PCA python package (https://github.com/ganguli-lab/twpca)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#suppress all tensorflow warnings (largely related to compatability with v2)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.ndimage.filters\n",
    "import matplotlib.pyplot as plt\n",
    "from twpca import TWPCA\n",
    "from twpca.regularizers import curvature\n",
    "from characterDefinitions import getHandwritingCharacterDefinitions\n",
    "from characterDefinitionsOrig import getHandwritingCharacterDefinitionsOrig\n",
    "\n",
    "#point this towards the top level dataset directory\n",
    "rootDir = os.path.expanduser('.') + '/handwritingBCIData/'\n",
    "\n",
    "#this line ensures that tensorflow will only use GPU 0 (keeps it from taking over all the GPUs in a multi-gpu setup)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "#defines all the sessions that will be time-warped\n",
    "dataDirs = ['t5.2019.05.08','t5.2019.11.25','t5.2019.12.09','t5.2019.12.11','t5.2019.12.18',\n",
    "            't5.2019.12.20','t5.2020.01.06','t5.2020.01.08','t5.2020.01.13','t5.2020.01.15']\n",
    "dataDirs = ['IamOnline1','IamOnline2','IamOnline3','IamOnline4',\n",
    "           'IamOnline5','IamOnline6','IamOnline7','IamOnline8','IamOnline9','IamOnline10','IamOnline11','IamOnline12']\n",
    "\n",
    "dataDirs = ['IamOnline1','IamOnline2','IamOnline3','IamOnline4', 'IamOnline5','IamOnline6']\n",
    "dataDirs = ['IamOnline3']\n",
    "\n",
    "#dataDirs = ['IamOnline', 't5.2019.05.08'] # 'IamOnline', 't5.2019.05.08'\n",
    "\n",
    "#saves all time-warped data in this folder\n",
    "if not os.path.isdir(rootDir + 'RNNTrainingSteps/Step1_TimeWarping'):\n",
    "    os.mkdir(rootDir + 'RNNTrainingSteps/Step1_TimeWarping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is  IamOnline3\n",
      "Warping dataset: IamOnline3\n",
      "Loaded Iamonline data\n",
      "Warping character: a\n",
      "Warping character: b\n",
      "Warping character: c\n",
      "Warping character: d\n",
      "Warping character: e\n",
      "Warping character: f\n",
      "Warping character: g\n",
      "Warping character: h\n",
      "Warping character: i\n",
      "Warping character: j\n",
      "Warping character: k\n",
      "Warping character: l\n",
      "Warping character: m\n",
      "Warping character: n\n",
      "Warping character: o\n",
      "Warping character: p\n",
      "Warping character: q\n",
      "Warping character: r\n",
      "Warping character: s\n",
      "Warping character: t\n",
      "Warping character: u\n",
      "Warping character: v\n",
      "Warping character: w\n",
      "Warping character: x\n",
      "Warping character: y\n",
      "Warping character: z\n",
      "Warping character: greaterThan\n",
      "Warping character: comma\n",
      "Warping character: apostrophe\n",
      "Warping character: tilde\n",
      "Warping character: questionMark\n",
      "Saving ./handwritingBCIData/RNNTrainingSteps/Step1_TimeWarping/IamOnline3_warpedCubes.mat\n"
     ]
    }
   ],
   "source": [
    "#Time-warp all singleLetters.mat files and save them to the Step1_TimeWarping folder\n",
    "for dataDir in dataDirs:\n",
    "    \n",
    "    #defines the list of all 31 characters and what to call them\n",
    "    if \"IamOnline\" in dataDir:\n",
    "      print(\"Data directory is \", dataDir)\n",
    "      charDef = getHandwritingCharacterDefinitions()\n",
    "    else:\n",
    "      charDef = getHandwritingCharacterDefinitionsOrig() \n",
    "    print('Warping dataset: ' + dataDir)\n",
    "    \n",
    "    #Because baseline firing rates drift over time, we normalize each electrode's firing rate by subtracting\n",
    "    #its mean firing rate within each block of data (re-centering it). We also divide by each electrode's standard deviation \n",
    "    #to normalize the units.\n",
    "    if \"IamOnline\" in dataDir:\n",
    "  #     dat =  scipy.io.loadmat(rootDir+'Datasets/'+'t5.2019.05.08'+'/singleLetters.mat')   # Template is required to overwrite\n",
    "       dat1 = scipy.io.loadmat(rootDir+'Datasets/'+dataDir+'/'+'singleChar_IamOnline.mat') # with new data\n",
    "       print(\"Loaded Iamonline data\")\n",
    "#       for char in charDef['charList']:\n",
    "#         neuralCube = dat1['neuralActivityCube_'+char].astype(np.float64)\n",
    "    else:\n",
    "        dat =  scipy.io.loadmat(rootDir+'Datasets/'+dataDir+'/singleLetters.mat')\n",
    "        for char in charDef['charList']:\n",
    "          neuralCube = dat['neuralActivityCube_'+char].astype(np.float64)\n",
    "\n",
    "            #get the trials that belong to this character\n",
    "          trlIdx = []\n",
    "          for t in range(dat['characterCues'].shape[0]):\n",
    "            if dat['characterCues'][t,0]==char:\n",
    "                trlIdx.append(t)\n",
    "\n",
    "          #get the block that each trial belonged to\n",
    "          blockIdx = dat['blockNumsTimeSeries'][dat['goPeriodOnsetTimeBin'][trlIdx]]\n",
    "          blockIdx = np.squeeze(blockIdx)\n",
    "\n",
    "          #subtract block-specific means from each trial \n",
    "          for b in range(dat['blockList'].shape[0]):\n",
    "            trialsFromThisBlock = np.squeeze(blockIdx==dat['blockList'][b])\n",
    "            neuralCube[trialsFromThisBlock,:,:] -= dat['meansPerBlock'][np.newaxis,b,:]\n",
    "\n",
    "          #divide by standard deviation to normalize the units\n",
    "          neuralCube = neuralCube / dat['stdAcrossAllData'][np.newaxis,:,:]\n",
    "\n",
    "          #replace the original cube with this newly normalized one\n",
    "          dat['neuralActivityCube_'+char] = neuralCube\n",
    "    \n",
    "    alignedDat = {}\n",
    "    \n",
    "    #The following warps each character one at a time. \n",
    "    #(this is slow, and could be sped up significantly by warping multiple characters in parallel)\n",
    "    for char in charDef['charList']:\n",
    "        print('Warping character: ' + char)\n",
    "\n",
    "        #Clears the previous character's graph\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        #Number of factors used to denoise the data while time-warping (by approximating data with low-rank matrices)\n",
    "        n_components = 5\n",
    "\n",
    "        #Adds an L1 penalty on the second order finite difference of the warping functions.\n",
    "        #This encourages the warping functions to be piecewise linear.\n",
    "        warp_regularizer = curvature(scale=0.001, power=1)\n",
    "\n",
    "        #Adds an L2 penatly on the second order finite difference of the temporal factors.\n",
    "        #Encourages the temporal factors to be smooth in time.\n",
    "        time_regularizer = curvature(scale=1.0, power=2, axis=0)\n",
    "\n",
    "        # Smooths the binned spike counts before time-warping to denoise them (this step is key!)\n",
    "        if \"IamOnline\" in dataDir:\n",
    "          smoothed_spikes = scipy.ndimage.filters.gaussian_filter1d(dat1['neuralActivityCube_'+char], 3.0, axis=1)\n",
    "        else:\n",
    "          smoothed_spikes = scipy.ndimage.filters.gaussian_filter1d(dat['neuralActivityCube_'+char], 3.0, axis=1)\n",
    "\n",
    "        # fit time-warping model\n",
    "        model = TWPCA(smoothed_spikes, \n",
    "                      n_components, \n",
    "                      warp_regularizer=warp_regularizer, \n",
    "                      time_regularizer=time_regularizer).fit(progressbar=False)\n",
    "\n",
    "        # use the model object to align data \n",
    "        if \"IamOnline\" in dataDir:\n",
    "           estimated_aligned_data = model.transform(dat1['neuralActivityCube_'+char])\n",
    "        else: \n",
    "           estimated_aligned_data = model.transform(dat['neuralActivityCube_'+char])\n",
    "        smoothed_aligned_data = scipy.ndimage.filters.gaussian_filter1d(estimated_aligned_data, 3.0, axis=1)\n",
    "\n",
    "        #store aligned data and time-warping functions\n",
    "        alignedDat[char] = estimated_aligned_data\n",
    "        alignedDat[char+'_T'] = model.params['warp'].T.copy()\n",
    "\n",
    "        #only make plots for the first session (otherwise the notebook gets too big)\n",
    "        if dataDir!='t5.2019.05.08':\n",
    "            continue\n",
    "            \n",
    "        #plot the warping functions to make sure they look reasonable (should be subtle deviations from the identity line)\n",
    "        plt.figure(figsize=(14,4))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.plot(model.params['warp'].T, alpha=1);\n",
    "        plt.axis('square')\n",
    "        plt.xlabel('Clock time')\n",
    "        plt.ylabel('Aligned time')\n",
    "        plt.xlim(0, model.params['warp'].T.shape[0]);\n",
    "        plt.ylim(0, model.params['warp'].T.shape[0])\n",
    "        plt.title('Learned warping functions')\n",
    "        \n",
    "        #It's helpful also to visualize how the major dimensions in the data were aligned\n",
    "        #We chose dimension 2 here, because the top dimension isn't as informative (it's just a large spike at movement onset)\n",
    "        neuron_factors = model.params['neuron']\n",
    "        plt.subplot(1,3,2)\n",
    "        for t in range(estimated_aligned_data.shape[0]):\n",
    "            thisTrialActivity = np.matmul(smoothed_spikes[t,:,:], neuron_factors)\n",
    "            plt.plot(thisTrialActivity[:,1])\n",
    "            \n",
    "        plt.title('Unwarped Trials')\n",
    "        plt.xlabel('Time Step (10 ms)')\n",
    "        plt.ylabel('Activity in Top Neural Dimension #2')\n",
    "        \n",
    "        plt.subplot(1,3,3)\n",
    "        for t in range(estimated_aligned_data.shape[0]):\n",
    "            thisTrialWarpedActivity = np.matmul(smoothed_aligned_data[t,:,:], neuron_factors)\n",
    "            plt.plot(thisTrialWarpedActivity[:,1])\n",
    "        \n",
    "        plt.title('Warped Trials')\n",
    "        plt.xlabel('Time Step (10 ms)')\n",
    "        plt.ylabel('Activity in Top Neural Dimension #2')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    #save time-warped characters as a .mat file        \n",
    "    fileName = rootDir + 'RNNTrainingSteps/Step1_TimeWarping/' + dataDir + '_warpedCubes.mat'\n",
    "    print('Saving ' + fileName)\n",
    "    scipy.io.savemat(fileName, alignedDat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
